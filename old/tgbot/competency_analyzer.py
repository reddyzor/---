import asyncio
import logging
import os
from typing import Dict, Tuple, List
import pandas as pd
from docx import Document
import aiohttp
import json
import uuid
from datetime import datetime
import sys
import os
import time
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from search_optimized import AsyncGigaChat, load_triggers, load_transcript, analyze_text_optimized, format_simple_report

class CompetencyAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –≤ Telegram –±–æ—Ç"""
    
    def __init__(self):
        self.giga_chat = None
        self.cache = {}  # –ö—ç—à –¥–ª—è —É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø–∞—Ä
        self.stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'api_errors': 0,
            'start_time': None,
            'end_time': None
        }
        
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GigaChat"""
        self.giga_chat = AsyncGigaChat()
        await self.giga_chat.initialize()
        
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        if self.giga_chat:
            await self.giga_chat.close()
            
    async def analyze_competencies(self, trans_file_path: str, triggers_file_path: str) -> Tuple[str, str, Dict]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç, –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –∏ –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            trans_file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ç–µ–∫—Å—Ç–æ–º –≤—Å—Ç—Ä–µ—á–∏
            triggers_file_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ç—Ä–∏–≥–≥–µ—Ä–∞–º–∏
            
        Returns:
            Tuple[str, str, Dict]: (–ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç, –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ, –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞)
        """
        try:
            self.stats['start_time'] = time.time()
            print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã
            print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–∏–≥–≥–µ—Ä—ã: {triggers_file_path}")
            triggers = load_triggers(triggers_file_path)
            print(f"‚úÖ –¢—Ä–∏–≥–≥–µ—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(triggers)} –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π")
            
            print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç: {trans_file_path}")
            full_text = load_transcript(trans_file_path)
            print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –≥–ª–∞–≤–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
            print("üéØ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –≥–ª–∞–≤–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞ (—É –∫–æ–≥–æ –±–æ–ª—å—à–µ —Ä–µ–ø–ª–∏–∫)")
            from search_optimized import filter_by_main_speaker
            text = filter_by_main_speaker(full_text)  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –≥–ª–∞–≤–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
            print(f"‚úÖ –¢–µ–∫—Å—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω: {len(full_text)} -> {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            if len(text.strip()) == 0:
                print("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ü–£–°–¢–û–ô!")
                return "–û—à–∏–±–∫–∞: –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª", "–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞"
            logging.info(f"–ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π: {len(full_text)} -> {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
            print("ü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º analyze_text_optimized...")
            analysis = await analyze_text_optimized(text, triggers, self.giga_chat)
            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(analysis)} –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
            self.update_stats_from_analysis(analysis)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç (–∫–∞–∫ –≤ REPORT.txt)
            full_report = self._create_detailed_report(analysis, trans_file_path, triggers_file_path)
            
            # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (–æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å)
            summary = self._create_summary(analysis)
            
            self.stats['end_time'] = time.time()
            return full_report, summary, analysis
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π: {e}")
            raise
    
    def get_similarity_score_cached(self, phrase: str, trigger: str) -> int:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ü–µ–Ω–∫—É —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = (phrase, trigger)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if cache_key in self.cache:
            self.stats['cache_hits'] += 1
            return self.cache[cache_key]
        
        self.stats['total_requests'] += 1
        # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –≤—ã–∑–æ–≤ API, –ø–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
        return 0
    
    def update_stats_from_analysis(self, analysis: Dict):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        if '_detailed_stats' in analysis:
            stats = analysis['_detailed_stats']
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º: –±–µ—Ä–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ GigaChat –∏ –∫—ç—à–∞
            self.stats['total_requests'] = self.giga_chat.total_requests if hasattr(self.giga_chat, 'total_requests') else 0
            self.stats['cache_hits'] = stats.get('similarity_cache_hits', 0)
            self.stats['api_errors'] = 0  # –ü–æ–∫–∞ –Ω–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –æ—à–∏–±–∫–∏ API
    
    def print_statistics(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        duration = self.stats['end_time'] - self.stats['start_time'] if self.stats['end_time'] else 0
        
        print("=== –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–ë–û–¢–´ ===")
        print(f"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API: {self.stats['total_requests']}")
        print(f"–ü–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫—ç—à: {self.stats['cache_hits']}")
        print(f"–û—à–∏–±–æ–∫ API: {self.stats['api_errors']}")
        print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫—É–Ω–¥")
        
        if self.stats['total_requests'] > 0:
            cache_hit_rate = (self.stats['cache_hits'] / (self.stats['cache_hits'] + self.stats['total_requests'])) * 100
            print(f"–ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫—ç—à: {cache_hit_rate:.1f}%")
    
    def _generate_positive_alternative(self, negative_phrase: str, indicator: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É –¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π —Ñ—Ä–∞–∑—ã"""
        alternatives = {
            "–ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è": {
                "—è –Ω–µ –∑–Ω–∞—é": "—è –∏–∑—É—á—É —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å",
                "—è –Ω–µ –ø–æ–Ω–∏–º–∞—é": "–¥–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ",
                "—ç—Ç–æ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ": "—ç—Ç–æ —Å–ª–æ–∂–Ω–∞—è –∑–∞–¥–∞—á–∞, –Ω–æ –º—ã –º–æ–∂–µ–º –Ω–∞–π—Ç–∏ —Ä–µ—à–µ–Ω–∏–µ",
                "—è –Ω–µ –º–æ–≥—É": "–º–Ω–µ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∏–∑—É—á–µ–Ω–∏–µ",
                "—ç—Ç–æ –Ω–µ –º–æ—è –ø—Ä–æ–±–ª–µ–º–∞": "—è –ø–æ–º–æ–≥—É —Ä–µ—à–∏—Ç—å —ç—Ç—É –∑–∞–¥–∞—á—É",
                "—è –Ω–µ —Ö–æ—á—É": "—è –≥–æ—Ç–æ–≤ –æ–±—Å—É–¥–∏—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã",
                "—ç—Ç–æ –≥–ª—É–ø–æ": "—ç—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∏–¥–µ—è, –¥–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º",
                "–≤—ã –Ω–µ–ø—Ä–∞–≤—ã": "—É –Ω–∞—Å —Ä–∞–∑–Ω—ã–µ —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è, –¥–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º",
                "—ç—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç": "–¥–∞–≤–∞–π—Ç–µ –Ω–∞–π–¥–µ–º –¥—Ä—É–≥–æ–π –ø–æ–¥—Ö–æ–¥",
                "—è –Ω–µ —Å–æ–≥–ª–∞—Å–µ–Ω": "—É –º–µ–Ω—è –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏—è",
                "—è –Ω–µ —É–º–µ—é": "—è –Ω–∞—É—á—É—Å—å —ç—Ç–æ–º—É",
                "—ç—Ç–æ –Ω–µ –º–æ–µ": "—è –≥–æ—Ç–æ–≤ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å",
                "—è –Ω–µ —Ö–æ—á—É –≥–æ–≤–æ—Ä–∏—Ç—å": "—è –≥–æ—Ç–æ–≤ –ø–æ–¥–µ–ª–∏—Ç—å—Å—è —Å–≤–æ–∏–º–∏ –º—ã—Å–ª—è–º–∏",
                "—ç—Ç–æ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω–æ": "–¥–∞–≤–∞–π—Ç–µ –Ω–∞–π–¥–µ–º —Å–º—ã—Å–ª –≤ —ç—Ç–æ–º",
                "—è –Ω–µ —Ö–æ—á—É —Å–ª—É—à–∞—Ç—å": "—è –≥–æ—Ç–æ–≤ –≤—ã—Å–ª—É—à–∞—Ç—å –≤–∞—à—É —Ç–æ—á–∫—É –∑—Ä–µ–Ω–∏—è"
            },
            "–õ–∏–¥–µ—Ä—Å—Ç–≤–æ": {
                "—è –Ω–µ –º–æ–≥—É —Ä–µ—à–∏—Ç—å": "—è –∏–∑—É—á—É –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ –ø—Ä–∏–º—É —Ä–µ—à–µ–Ω–∏–µ",
                "—ç—Ç–æ –Ω–µ –º–æ—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å": "—è –≤–æ–∑—å–º—É –Ω–∞ —Å–µ–±—è —ç—Ç—É –∑–∞–¥–∞—á—É",
                "—è –Ω–µ —Ö–æ—á—É —Ä—É–∫–æ–≤–æ–¥–∏—Ç—å": "—è –≥–æ—Ç–æ–≤ –≤–∑—è—Ç—å –Ω–∞ —Å–µ–±—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ",
                "–ø—É—Å—Ç—å –¥—Ä—É–≥–∏–µ —Ä–µ—à–∞—é—Ç": "—è –≤–æ–∑—å–º—É –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—É –≤ —Å–≤–æ–∏ —Ä—É–∫–∏",
                "—è –Ω–µ –∑–Ω–∞—é —á—Ç–æ –¥–µ–ª–∞—Ç—å": "—è –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–∏—Ç—É–∞—Ü–∏—é –∏ –æ–ø—Ä–µ–¥–µ–ª—é –ø–ª–∞–Ω",
                "—ç—Ç–æ —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ": "—ç—Ç–æ –≤—ã–∑–æ–≤, –∫–æ—Ç–æ—Ä—ã–π –º—ã –ø—Ä–µ–æ–¥–æ–ª–µ–µ–º",
                "—è –Ω–µ –≥–æ—Ç–æ–≤": "—è –ø–æ–¥–≥–æ—Ç–æ–≤–ª—é—Å—å –∏ –±—É–¥—É –≥–æ—Ç–æ–≤",
                "–ø—É—Å—Ç—å –∫—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–π": "—è –≥–æ—Ç–æ–≤ –≤–∑—è—Ç—å –Ω–∞ —Å–µ–±—è —ç—Ç—É —Ä–æ–ª—å",
                "—è –Ω–µ —Ö–æ—á—É –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏—è": "—è –≥–æ—Ç–æ–≤ –≤–∑—è—Ç—å –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ —Ä–µ—à–µ–Ω–∏–µ",
                "—ç—Ç–æ –Ω–µ –º–æ–µ –¥–µ–ª–æ": "—è –≤–æ–∑—å–º—É –Ω–∞ —Å–µ–±—è —ç—Ç—É –∑–∞–¥–∞—á—É",
                "—è –Ω–µ —Ö–æ—á—É –∫–æ–º–∞–Ω–¥–æ–≤–∞—Ç—å": "—è –≥–æ—Ç–æ–≤ –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É –∫–æ–º–∞–Ω–¥—ã",
                "–ø—É—Å—Ç—å —Å–∞–º–∏ —Ä–∞–∑–±–∏—Ä–∞—é—Ç—Å—è": "—è –ø–æ–º–æ–≥—É –∫–æ–º–∞–Ω–¥–µ –Ω–∞–π—Ç–∏ —Ä–µ—à–µ–Ω–∏–µ"
            },
            "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å": {
                "—è –Ω–µ —Ö–æ—á—É –º–µ–Ω—è—Ç—å—Å—è": "—è –≥–æ—Ç–æ–≤ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ –Ω–æ–≤—ã–º —É—Å–ª–æ–≤–∏—è–º",
                "—ç—Ç–æ –Ω–µ –¥–ª—è –º–µ–Ω—è": "—è –∏–∑—É—á—É –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏",
                "—è –ø—Ä–∏–≤—ã–∫ –ø–æ-–¥—Ä—É–≥–æ–º—É": "—è –≥–æ—Ç–æ–≤ –∏–∑—É—á–∏—Ç—å –Ω–æ–≤—ã–µ –ø–æ–¥—Ö–æ–¥—ã",
                "—ç—Ç–æ —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ": "—è –æ—Å–≤–æ—é –Ω–æ–≤—ã–µ –Ω–∞–≤—ã–∫–∏",
                "—è –Ω–µ –ø–æ–Ω–∏–º–∞—é –∑–∞—á–µ–º": "—è –∏–∑—É—á—É –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –Ω–æ–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞",
                "—ç—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç": "—è –Ω–∞–π–¥—É —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∞–¥–∞–ø—Ç–∞—Ü–∏–∏",
                "—è –Ω–µ —Ö–æ—á—É —É—á–∏—Ç—å—Å—è": "—è –≥–æ—Ç–æ–≤ –æ—Å–≤–æ–∏—Ç—å –Ω–æ–≤—ã–µ –Ω–∞–≤—ã–∫–∏",
                "—ç—Ç–æ –Ω–µ –º–æ–π —Å—Ç–∏–ª—å": "—è –≥–æ—Ç–æ–≤ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥",
                "—è –Ω–µ —Ö–æ—á—É –ø—Ä–æ–±–æ–≤–∞—Ç—å": "—è –≥–æ—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å",
                "—ç—Ç–æ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç": "—è –Ω–∞–π–¥—É —Å–ø–æ—Å–æ–± –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è"
            },
            "–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º": {
                "—è –Ω–µ –∑–Ω–∞—é –∫–∞–∫ —Ä–µ—à–∏—Ç—å": "—è –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø—Ä–æ–±–ª–µ–º—É –∏ –Ω–∞–π–¥—É —Ä–µ—à–µ–Ω–∏–µ",
                "—ç—Ç–æ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ": "—è –Ω–∞–π–¥—É –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø—É—Ç–∏ —Ä–µ—à–µ–Ω–∏—è",
                "—è –Ω–µ –º–æ–≥—É —ç—Ç–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å": "—è –∏–∑—É—á—É –ø—Ä–∏—á–∏–Ω—ã –∏ –Ω–∞–π–¥—É —Å–ø–æ—Å–æ–± –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è",
                "—ç—Ç–æ –Ω–µ –º–æ—è –ø—Ä–æ–±–ª–µ–º–∞": "—è –ø–æ–º–æ–≥—É —Ä–µ—à–∏—Ç—å —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É",
                "—è –Ω–µ —Ö–æ—á—É —ç—Ç–∏–º –∑–∞–Ω–∏–º–∞—Ç—å—Å—è": "—è –≥–æ—Ç–æ–≤ –≤–∑—è—Ç—å –Ω–∞ —Å–µ–±—è —Ä–µ—à–µ–Ω–∏–µ —ç—Ç–æ–π –∑–∞–¥–∞—á–∏",
                "—ç—Ç–æ –Ω–µ –º–æ—è –≤–∏–Ω–∞": "—è –ø–æ–º–æ–≥—É –Ω–∞–π—Ç–∏ —Ä–µ—à–µ–Ω–∏–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø—Ä–∏—á–∏–Ω",
                "—è –Ω–µ —Ö–æ—á—É —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è": "—è –≥–æ—Ç–æ–≤ –≥–ª—É–±–æ–∫–æ –∏–∑—É—á–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É",
                "—ç—Ç–æ –Ω–µ –º–æ–µ –¥–µ–ª–æ": "—è –≤–æ–∑—å–º—É –Ω–∞ —Å–µ–±—è —Ä–µ—à–µ–Ω–∏–µ —ç—Ç–æ–π –∑–∞–¥–∞—á–∏",
                "–ø—É—Å—Ç—å –∫—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–π —Ä–µ—à–∞–µ—Ç": "—è –≥–æ—Ç–æ–≤ –≤–∑—è—Ç—å –Ω–∞ —Å–µ–±—è —Ä–µ—à–µ–Ω–∏–µ"
            },
            "–†–∞–±–æ—Ç–∞ –≤ –∫–æ–º–∞–Ω–¥–µ": {
                "—è –Ω–µ —Ö–æ—á—É —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –∫–æ–º–∞–Ω–¥–µ": "—è –≥–æ—Ç–æ–≤ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–∞—Ç—å —Å –∫–æ–º–∞–Ω–¥–æ–π",
                "—è –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞—é –æ–¥–∏–Ω": "—è –≥–æ—Ç–æ–≤ –≤–Ω–µ—Å—Ç–∏ —Å–≤–æ–π –≤–∫–ª–∞–¥ –≤ –∫–æ–º–∞–Ω–¥–Ω—É—é —Ä–∞–±–æ—Ç—É",
                "—è –Ω–µ —Ö–æ—á—É –¥–µ–ª–∏—Ç—å—Å—è": "—è –≥–æ—Ç–æ–≤ –ø–æ–¥–µ–ª–∏—Ç—å—Å—è —Å–≤–æ–∏–º–∏ –∏–¥–µ—è–º–∏",
                "—ç—Ç–æ –Ω–µ –º–æ—è –∫–æ–º–∞–Ω–¥–∞": "—è –≥–æ—Ç–æ–≤ —Å—Ç–∞—Ç—å —á–∞—Å—Ç—å—é –∫–æ–º–∞–Ω–¥—ã",
                "—è –Ω–µ —Ö–æ—á—É –ø–æ–º–æ–≥–∞—Ç—å": "—è –≥–æ—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–ª–µ–≥",
                "–ø—É—Å—Ç—å —Å–∞–º–∏ —Ä–∞–∑–±–∏—Ä–∞—é—Ç—Å—è": "—è –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å –∫–æ–º–∞–Ω–¥–µ"
            },
            "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ": {
                "—è –Ω–µ —Ö–æ—á—É –¥—É–º–∞—Ç—å": "—è –≥–æ—Ç–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Ç—É–∞—Ü–∏—é",
                "—ç—Ç–æ –æ—á–µ–≤–∏–¥–Ω–æ": "–¥–∞–≤–∞–π—Ç–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —ç—Ç–æ –≥–ª—É–±–∂–µ",
                "—è –Ω–µ —Ö–æ—á—É –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å": "—è –≥–æ—Ç–æ–≤ –¥–µ—Ç–∞–ª—å–Ω–æ –∏–∑—É—á–∏—Ç—å –≤–æ–ø—Ä–æ—Å",
                "—ç—Ç–æ –Ω–µ –≤–∞–∂–Ω–æ": "–¥–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã",
                "—è –Ω–µ —Ö–æ—á—É —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è": "—è –≥–æ—Ç–æ–≤ –≥–ª—É–±–æ–∫–æ –∏–∑—É—á–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É"
            }
        }
        
        # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É
        for comp, phrases in alternatives.items():
            if comp.lower() in indicator.lower():
                for neg_phrase, pos_phrase in phrases.items():
                    if neg_phrase.lower() in negative_phrase.lower():
                        return pos_phrase
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—â—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É
        return f"–≤–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –º–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å –±–æ–ª–µ–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ"
            
    def _create_summary(self, analysis: Dict) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –ø–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º"""
        summary = "üìä –ö–†–ê–¢–ö–û–ï –†–ï–ó–Æ–ú–ï –ü–û –ö–û–ú–ü–ï–¢–ï–ù–¶–ò–Ø–ú\n\n"
        
        competency_scores = {}
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º
        for comp, data in analysis.items():
            if comp == '_detailed_stats':
                continue
                
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –ø–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
            indicator_scores = []
            courses_for_comp = set()
            
            for indicator, ind_data in data["indicators"].items():
                indicator_scores.append(ind_data['score'])
                if ind_data['courses']:
                    courses_for_comp.update(ind_data['courses'])
            
            if indicator_scores:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—É–º–º—É –≤—Å–µ—Ö –±–∞–ª–ª–æ–≤ –±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
                total_score = sum(indicator_scores)
                competency_scores[comp] = {
                    'score': total_score,
                    'courses': list(courses_for_comp),
                    'has_negative': any(ind_data['negative']['score'] > 0 for ind_data in data["indicators"].values())
                }
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –ø–æ –±–∞–ª–ª–∞–º
        sorted_competencies = sorted(competency_scores.items(), key=lambda x: x[1]['score'])
        
        for comp, data in sorted_competencies:
            score = data['score']
            courses = data['courses']
            has_negative = data['has_negative']
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Å—ã—Ä—ã—Ö —Å—É–º–º)
            if score >= 30:
                status = "‚úÖ –û—Ç–ª–∏—á–Ω–æ —Ä–∞–∑–≤–∏—Ç–∞"
                emoji = "üü¢"
            elif score >= 15:
                status = "üü° –¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è"
                emoji = "üü°"
            else:
                status = "‚ùå –¢—Ä–µ–±—É–µ—Ç —Ä–∞–∑–≤–∏—Ç–∏—è"
                emoji = "üî¥"
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ - —É–±–∏—Ä–∞–µ–º "/10" –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫ "X –±–∞–ª–ª–æ–≤"
            summary += f"{emoji} **{comp}** - {score:.1f} –±–∞–ª–ª–æ–≤\n"
            summary += f"   {status}\n"
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—É—Ä—Å—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ—è–≤–ª–µ–Ω–∏—è
            if has_negative and courses:
                summary += f"   üìö **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∫—É—Ä—Å—ã:**\n"
                for course in courses[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 3 –∫—É—Ä—Å–∞
                    summary += f"      ‚Ä¢ {course}\n"
                summary += "\n"
            elif score < 15 and courses:
                summary += f"   üìö **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∫—É—Ä—Å—ã:**\n"
                for course in courses[:3]:
                    summary += f"      ‚Ä¢ {course}\n"
                summary += "\n"
            else:
                summary += "\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ñ—Ä–∞–∑ –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤
            if has_negative:
                summary += f"   üí° **–ü—Ä–∏–º–µ—Ä—ã —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏:**\n"
                negative_examples = []
                for indicator, ind_data in analysis[comp]["indicators"].items():
                    for example in ind_data['negative']['examples'][:2]:  # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 2 –ø—Ä–∏–º–µ—Ä–∞
                        alternative = self._generate_positive_alternative(example['found'], indicator)
                        negative_examples.append(f"      ‚Ä¢ –í–º–µ—Å—Ç–æ: \"{example['found'][:50]}...\"\n        –ú–æ–∂–Ω–æ: \"{alternative}\"")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 3 –ø—Ä–∏–º–µ—Ä–∞
                for example in negative_examples[:3]:
                    summary += f"{example}\n"
                summary += "\n"
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        low_score_comps = [comp for comp, data in competency_scores.items() if data['score'] < 15]
        if low_score_comps:
            summary += "üí° **–û–ë–©–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**\n"
            summary += f"   ‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ä–∞–∑–≤–∏—Ç–∏–µ: {', '.join(low_score_comps[:3])}\n"
            summary += "   ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∫—É—Ä—Å—ã\n"
            summary += "   ‚Ä¢ –ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ –Ω–∞–≤—ã–∫–∏ –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π —Ä–∞–±–æ—Ç–µ\n\n"
        
        high_score_comps = [comp for comp, data in competency_scores.items() if data['score'] >= 30]
        if high_score_comps:
            summary += "üéâ **–°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´:**\n"
            summary += f"   ‚Ä¢ –û—Ç–ª–∏—á–Ω–æ —Ä–∞–∑–≤–∏—Ç—ã: {', '.join(high_score_comps[:3])}\n"
            summary += "   ‚Ä¢ –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å\n\n"
        
        return summary

    def _create_detailed_report(self, analysis: Dict, trans_file_path: str, triggers_file_path: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ REPORT.txt"""
        report = "üéØ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ö–û–ú–ü–ï–¢–ï–ù–¶–ò–ô\n\n"
        report += "=" * 80 + "\n"
        report += f"üìÅ –§–∞–π–ª –≤—Å—Ç—Ä–µ—á–∏: {trans_file_path}\n"
        report += f"üìÅ –§–∞–π–ª —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤: {triggers_file_path}\n"
        report += f"üìÖ –î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += "=" * 80 + "\n\n"
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π
        for comp, data in analysis.items():
            if comp == '_detailed_stats':
                continue
            
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ –±–∞–ª–ª–∞ –ø–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
            indicator_scores = []
            for indicator, ind_data in data["indicators"].items():
                indicator_scores.append(ind_data['score'])
            
            if indicator_scores:
                avg_score = sum(indicator_scores) / len(indicator_scores)
            else:
                avg_score = 0
            
            report += f"üèÜ {comp} - —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª {avg_score:.1f}\n"
            report += "=" * 80 + "\n\n"
            
            for indicator, ind_data in data["indicators"].items():
                report += f"üìä {indicator} - {ind_data['score']:.1f} –±–∞–ª–ª–∞\n"
                report += f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö: {ind_data['positive']['score']:.1f}\n"
                report += f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö: {ind_data['negative']['score']:.1f}\n"
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                if ind_data['positive']['examples']:
                    report += "   \n   ‚úÖ –ù–ê–ô–î–ï–ù–û –í –¢–ï–ö–°–¢–ï (–ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ):\n"
                    for example in ind_data['positive']['examples']:
                        report += f"      ‚Ä¢ \"{example['found'][:200]}...\"\n"
                        report += f"        –ü–æ—Ö–æ–∂–µ –Ω–∞: \"{example['original'][:100]}...\"\n"
                        report += f"        –ë–∞–ª–ª: {example['score']:.1f}\n\n"
                
                if ind_data['negative']['examples']:
                    report += "   \n   ‚ùå –ù–ê–ô–î–ï–ù–û –í –¢–ï–ö–°–¢–ï (–Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ):\n"
                    for example in ind_data['negative']['examples']:
                        report += f"      ‚Ä¢ \"{example['found'][:200]}...\"\n"
                        report += f"        –ü–æ—Ö–æ–∂–µ –Ω–∞: \"{example['original'][:100]}...\"\n"
                        report += f"        –ë–∞–ª–ª: -{example['score']:.1f}\n"
                        # –î–æ–±–∞–≤–ª—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É
                        alternative = self._generate_positive_alternative(example['found'], indicator)
                        report += f"        üí° –ú–æ–≥ –±—ã —Å–∫–∞–∑–∞—Ç—å: \"{alternative}\"\n\n"
                
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫—É—Ä—Å–∞–º
                if ind_data['courses']:
                    report += "   üí° –†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù–ù–´–ï –ö–£–†–°–´:\n"
                    for course in ind_data['courses']:
                        report += f"      ‚Ä¢ {course}\n"
                    if ind_data['negative']['score'] > 0:
                        report += f"      –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: –Ω–∞–π–¥–µ–Ω –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç—Ä–∏–≥–≥–µ—Ä (–±–∞–ª–ª: -{ind_data['negative']['score']:.1f})\n"
                    report += "\n"
                
                report += "-" * 70 + "\n\n"
            
            report += "\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if '_detailed_stats' in analysis:
            stats = analysis['_detailed_stats']
            report += "ÔøΩÔøΩ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò:\n"
            report += "=" * 80 + "\n"
            report += f"   –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {stats.get('processing_time', 0):.1f}—Å\n"
            report += f"   –í—Å–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π: {stats.get('total_comparisons', 0)}\n"
            report += f"   –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {stats.get('tokens_used', 0)}\n"
            report += f"   –†–∞–∑–º–µ—Ä –∫—ç—à–∞: {stats.get('cache_size', 0)}\n"
            report += f"   –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats.get('sentences_processed', 0)}\n"
            report += "=" * 80 + "\n\n"
        
        return report
    
    def save_results_to_files(self, analysis: Dict, trans_file_path: str, triggers_file_path: str, output_dir: str = "results"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–∞–π–ª—ã"""
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        report_file = os.path.join(output_dir, f"detailed_report_{timestamp}.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(self._create_detailed_report(analysis, trans_file_path, triggers_file_path))
        print(f"üìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ
        summary_file = os.path.join(output_dir, f"summary_{timestamp}.txt")
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(self._create_summary(analysis))
        print(f"üìÑ –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {summary_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats_file = os.path.join(output_dir, f"stats_{timestamp}.json")
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(self.stats, f, indent=2, ensure_ascii=False)
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {stats_file}")
    
    def create_csv_report(self, analysis: Dict, output_dir: str = "results"):
        """–°–æ–∑–¥–∞–µ—Ç CSV –æ—Ç—á–µ—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞"""
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        detailed_data = []
        summary_data = []
        
        for comp, data in analysis.items():
            if comp == '_detailed_stats':
                continue
                
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –ø–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
            indicator_scores = []
            for indicator, ind_data in data["indicators"].items():
                indicator_scores.append(ind_data['score'])
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                detailed_data.append({
                    'competency': comp,
                    'indicator': indicator,
                    'score': ind_data['score'],
                    'positive_score': ind_data['positive']['score'],
                    'negative_score': ind_data['negative']['score'],
                    'positive_examples_count': len(ind_data['positive']['examples']),
                    'negative_examples_count': len(ind_data['negative']['examples']),
                    'courses_count': len(ind_data['courses'])
                })
            
            if indicator_scores:
                avg_score = sum(indicator_scores) / len(indicator_scores)
                summary_data.append({
                    'competency': comp,
                    'avg_score': avg_score,
                    'indicators_count': len(indicator_scores),
                    'total_positive': sum(ind_data['positive']['score'] for ind_data in data["indicators"].values()),
                    'total_negative': sum(ind_data['negative']['score'] for ind_data in data["indicators"].values())
                })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        if detailed_data:
            df_detailed = pd.DataFrame(detailed_data)
            detailed_file = os.path.join(output_dir, f"detailed_analysis_{timestamp}.csv")
            df_detailed.to_csv(detailed_file, index=False, encoding='utf-8-sig')
            print(f"üìä –î–µ—Ç–∞–ª—å–Ω—ã–π CSV –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {detailed_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        if summary_data:
            df_summary = pd.DataFrame(summary_data)
            summary_file = os.path.join(output_dir, f"summary_analysis_{timestamp}.csv")
            df_summary.to_csv(summary_file, index=False, encoding='utf-8-sig')
            print(f"üìä –°–≤–æ–¥–Ω—ã–π CSV –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {summary_file}")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ Telegram –±–æ—Ç–µ
async def analyze_competencies_async(trans_file: str, triggers_file: str, save_files: bool = False) -> Tuple[str, str]:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π
    
    Args:
        trans_file: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ç–µ–∫—Å—Ç–æ–º –≤—Å—Ç—Ä–µ—á–∏
        triggers_file: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ç—Ä–∏–≥–≥–µ—Ä–∞–º–∏
        save_files: —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã
        
    Returns:
        Tuple[str, str]: (–ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç, –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ)
    """
    analyzer = CompetencyAnalyzer()
    try:
        await analyzer.initialize()
        full_report, summary, analysis = await analyzer.analyze_competencies(trans_file, triggers_file)
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        analyzer.print_statistics()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if save_files:
            analyzer.save_results_to_files(analysis, trans_file, triggers_file)
            analyzer.create_csv_report(analysis)
        
        return full_report, summary
    finally:
        await analyzer.close() 