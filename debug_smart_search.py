import asyncio
import logging
import time
from search import load_transcript, load_triggers, AsyncGigaChat
from smart_filter import SmartPhraseFilter

async def debug_analysis():
    """–û—Ç–ª–∞–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ —à–∞–≥–∞–º"""
    
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
    
    print("=== –û–¢–õ–ê–î–ö–ê –ê–ù–ê–õ–ò–ó–ê ===")
    
    try:
        # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
        print("1. –ó–∞–≥—Ä—É–∂–∞—é —Ñ–∞–π–ª—ã...")
        start_time = time.time()
        text = load_transcript('trans.docx')
        triggers = load_triggers('triggers.xlsx')
        print(f"‚úÖ –§–∞–π–ª—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞ {time.time() - start_time:.2f}—Å: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, {len(triggers)} –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π")
        
        # –®–∞–≥ 2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–º–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞
        print("2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é —É–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä...")
        start_time = time.time()
        smart_filter = SmartPhraseFilter()
        print(f"‚úÖ –£–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∑–∞ {time.time() - start_time:.2f}—Å")
        
        # –®–∞–≥ 3: –¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞ –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–º —Ç–µ–∫—Å—Ç–µ
        print("3. –¢–µ—Å—Ç–∏—Ä—É—é —Ñ–∏–ª—å—Ç—Ä...")
        test_phrases = text.split('.', 10)[:10]  # –ü–µ—Ä–≤—ã–µ 10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        meaningful_count = 0
        
        for i, phrase in enumerate(test_phrases):
            if phrase.strip():
                try:
                    start_time = time.time()
                    is_meaningful = smart_filter.is_meaningful_phrase_basic(phrase)
                    filter_time = time.time() - start_time
                    
                    if is_meaningful:
                        meaningful_count += 1
                    print(f"   –§—Ä–∞–∑–∞ {i+1} ({filter_time:.3f}—Å): {'‚úÖ' if is_meaningful else '‚ùå'} - {phrase[:50]}...")
                except Exception as e:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –≤ —Ñ—Ä–∞–∑–µ {i+1}: {e}")
        
        print(f"‚úÖ –§–∏–ª—å—Ç—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç. –ó–Ω–∞—á–∏–º—ã—Ö —Ñ—Ä–∞–∑: {meaningful_count}/{len(test_phrases)}")
        
        # –®–∞–≥ 4: –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ GigaChat
        print("4. –ü–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ GigaChat...")
        try:
            start_time = time.time()
            giga_chat = AsyncGigaChat()
            await giga_chat.initialize()
            init_time = time.time() - start_time
            print(f"‚úÖ GigaChat –ø–æ–¥–∫–ª—é—á–µ–Ω –∑–∞ {init_time:.2f}—Å")
            
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
            start_time = time.time()
            response = await giga_chat.send("–ü—Ä–∏–≤–µ—Ç, —ç—Ç–æ —Ç–µ—Å—Ç. –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ: —Ä–∞–±–æ—Ç–∞–µ—à—å?")
            request_time = time.time() - start_time
            print(f"‚úÖ –¢–µ—Å—Ç GigaChat ({request_time:.2f}—Å): {response[:50]}...")
            
            await giga_chat.close()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ GigaChat: {e}")
            return
        
        # –®–∞–≥ 5: –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        print("5. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        
        # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ —Ñ—Ä–∞–∑ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
        sentences = text.split('.')
        meaningful_sentences = []
        
        print("   –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–µ—Ä–≤—ã–µ 100 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π...")
        start_time = time.time()
        
        for i, sent in enumerate(sentences[:100]):
            if sent.strip() and smart_filter.is_meaningful_phrase_basic(sent):
                meaningful_sentences.append(sent)
            
            if i % 25 == 0:
                print(f"      –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i}/100 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π...")
        
        filter_time = time.time() - start_time
        
        # –°—á–∏—Ç–∞–µ–º –º–∞—Ä–∫–µ—Ä—ã
        total_markers = 0
        for comp_data in triggers.values():
            for ind_data in comp_data.values():
                total_markers += len(ind_data['positive_markers']) + len(ind_data['negative_markers'])
        
        estimated_comparisons = len(meaningful_sentences) * total_markers
        
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   - –í—Å–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(sentences)}")
        print(f"   - –ó–Ω–∞—á–∏–º—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–ø–µ—Ä–≤—ã–µ 100): {len(meaningful_sentences)}")
        print(f"   - –í—Ä–µ–º—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ 100 –ø—Ä–µ–¥–ª.: {filter_time:.2f}—Å")
        print(f"   - –í—Å–µ–≥–æ –º–∞—Ä–∫–µ—Ä–æ–≤: {total_markers}")
        print(f"   - –û–∂–∏–¥–∞–µ–º—ã–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (100 –ø—Ä–µ–¥–ª.): {estimated_comparisons}")
        
        # –≠–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è –Ω–∞ –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        full_meaningful = int(len(meaningful_sentences) * len(sentences) / 100)
        full_comparisons = full_meaningful * total_markers
        estimated_time = (filter_time * len(sentences) / 100) + (full_comparisons * 0.1)  # 0.1—Å –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        
        print(f"   - –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Ç—Ä–µ–±—É–µ—Ç: ~{full_comparisons} —Å—Ä–∞–≤–Ω–µ–Ω–∏–π")
        print(f"   - –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: ~{estimated_time/60:.1f} –º–∏–Ω—É—Ç")
        
        if estimated_time > 300:  # –ë–æ–ª—å—à–µ 5 –º–∏–Ω—É—Ç
            print("‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –û—á–µ–Ω—å –¥–æ–ª–≥–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞! –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è.")
        
        print("\n‚úÖ –û—Ç–ª–∞–¥–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç.")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(debug_analysis()) 