import asyncio
from search import load_transcript, load_triggers, check_semantic_similarity, preprocess_text
from difflib import SequenceMatcher

async def test_matching():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –º–µ–∂–¥—É —Ä–µ–∞–ª—å–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –∏ –º–∞—Ä–∫–µ—Ä–∞–º–∏"""
    
    print("=== –¢–ï–°–¢ –ü–û–ò–°–ö–ê –°–û–í–ü–ê–î–ï–ù–ò–ô ===")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    try:
        text = load_transcript('trans.docx')
        triggers = load_triggers('triggers.xlsx')
        
        print(f"‚úÖ –¢–µ–∫—Å—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚úÖ –¢—Ä–∏–≥–≥–µ—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(triggers)} –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π")
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
        sentences = preprocess_text(text)
        print(f"\nüìù –ü–µ—Ä–≤—ã–µ 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞:")
        for i, sent in enumerate(sentences[:5]):
            print(f"{i+1}. {sent[:100]}...")
        
        # –ë–µ—Ä–µ–º –º–∞—Ä–∫–µ—Ä—ã –∏–∑ –ø–µ—Ä–≤–æ–π –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
        first_comp = list(triggers.keys())[0]
        first_indicator = list(triggers[first_comp].keys())[0]
        pos_markers = triggers[first_comp][first_indicator]['positive_markers']
        
        print(f"\nüéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–µ–π: {first_comp}")
        print(f"üìä –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä: {first_indicator}")
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤: {len(pos_markers)}")
        
        print(f"\nüîç –ü–µ—Ä–≤—ã–µ 3 –º–∞—Ä–∫–µ—Ä–∞:")
        markers_list = list(pos_markers.keys())[:3]
        for i, marker in enumerate(markers_list):
            print(f"{i+1}. {marker[:100]}...")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        print(f"\nüß™ –¢–ï–°–¢ –°–û–í–ü–ê–î–ï–ù–ò–ô:")
        best_matches = []
        
        for sent in sentences[:10]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            for marker in markers_list[:3]:  # –° –ø–µ—Ä–≤—ã–º–∏ 3 –º–∞—Ä–∫–µ—Ä–∞–º–∏
                similarity = SequenceMatcher(None, sent.lower(), marker.lower()).ratio()
                if similarity > 0.3:  # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –∫–∞–∫–æ–µ-—Ç–æ —Å—Ö–æ–¥—Å—Ç–≤–æ
                    best_matches.append((sent, marker, similarity))
        
        if best_matches:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(best_matches)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π:")
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞
            best_matches.sort(key=lambda x: x[2], reverse=True)
            for i, (sent, marker, sim) in enumerate(best_matches[:5]):
                print(f"{i+1}. –°—Ö–æ–¥—Å—Ç–≤–æ: {sim:.3f} ({sim*100:.1f}%)")
                print(f"   –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {sent[:80]}...")
                print(f"   –ú–∞—Ä–∫–µ—Ä: {marker[:80]}...")
                print()
        else:
            print("‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        # –ü—Ä–æ–≤–µ—Ä–∏–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
        print(f"\nüéØ –ü–†–û–í–ï–†–ö–ê –ö–û–ù–ö–†–ï–¢–ù–´–• –§–†–ê–ó:")
        test_phrases = [
            "—è –ø–æ–Ω–∏–º–∞—é —á—Ç–æ –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏ —è —Å–∏–ª—ë–Ω",
            "—è —Å—Ç–∞—Ä–∞—é—Å—å –ø–æ–Ω—è—Ç—å –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–∞", 
            "—Ä–∞–±–æ—Ç–∞–µ–º —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏",
            "–ø–æ–¥–µ–ª–∏—Ç—å—Å—è –æ–ø—ã—Ç–æ–º",
            "–∫–æ–º–∞–Ω–¥–∞ –¥—Ä—É–∂–Ω–∞—è"
        ]
        
        for phrase in test_phrases:
            for marker in markers_list[:2]:
                similarity = SequenceMatcher(None, phrase.lower(), marker.lower()).ratio()
                print(f"'{phrase}' ‚Üí '{marker[:50]}...' = {similarity:.3f} ({similarity*100:.1f}%)")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    asyncio.run(test_matching()) 