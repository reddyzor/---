def format_detailed_report(analysis: dict, SEMANTIC_THRESHOLD: float, MAX_POSITIVE_MATCHES: int, MAX_NEGATIVE_MATCHES: int, MIN_PERCENTAGE: int, MAX_PERCENTAGE: int) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π"""
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    detailed_stats = analysis.get('_detailed_stats', {})
    filter_stats = detailed_stats.get('filter_stats', {})
    competency_stats = detailed_stats.get('competency_stats', {})
    
    report = "üîß –ü–û–î–†–û–ë–ù–´–ô –û–¢–ß–ï–¢ –ü–û –ê–ù–ê–õ–ò–ó–£ –ö–û–ú–ü–ï–¢–ï–ù–¶–ò–ô\n\n"
    report += "=" * 80 + "\n"
    report += "üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –§–ò–õ–¨–¢–†–ê–¶–ò–ò –¢–ï–ö–°–¢–ê\n"
    report += "=" * 80 + "\n\n"
    
    if filter_stats:
        report += f"–í—Å–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ: {filter_stats.get('total_sentences', 0)}\n"
        report += f"–ü—Ä–æ—à–ª–∏ —É–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä: {filter_stats.get('passed_filter', 0)}\n"
        report += f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º: {filter_stats.get('filtered_by_pattern', 0)}\n"
        report += f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ –¥–ª–∏–Ω–µ: {filter_stats.get('filtered_by_length', 0)}\n"
        report += f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞–º: {filter_stats.get('filtered_by_stopwords', 0)}\n"
        report += f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–∏: {filter_stats.get('filtered_by_morphology', 0)}\n\n"
        
        # –ü—Ä–∏–º–µ—Ä—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
        filtered_examples = filter_stats.get('filtered_examples', {})
        
        if filtered_examples.get('pattern'):
            report += "üö´ –ü–†–ò–ú–ï–†–´ –§–†–ê–ó, –û–¢–§–ò–õ–¨–¢–†–û–í–ê–ù–ù–´–• –ü–û –ü–ê–¢–¢–ï–†–ù–ê–ú:\n"
            for i, example in enumerate(filtered_examples['pattern'], 1):
                report += f"  {i}. \"{example}...\"\n"
            report += "\n"
        
        if filtered_examples.get('length'):
            report += "üìè –ü–†–ò–ú–ï–†–´ –§–†–ê–ó, –û–¢–§–ò–õ–¨–¢–†–û–í–ê–ù–ù–´–• –ü–û –î–õ–ò–ù–ï (< 30 —Å–∏–º–≤–æ–ª–æ–≤):\n"
            for i, example in enumerate(filtered_examples['length'], 1):
                report += f"  {i}. \"{example}...\"\n"
            report += "\n"
        
        if filtered_examples.get('stopwords'):
            report += "‚õî –ü–†–ò–ú–ï–†–´ –§–†–ê–ó, –û–¢–§–ò–õ–¨–¢–†–û–í–ê–ù–ù–´–• –ü–û –°–¢–û–ü-–°–õ–û–í–ê–ú (>70%):\n"
            for i, example in enumerate(filtered_examples['stopwords'], 1):
                report += f"  {i}. \"{example}...\"\n"
            report += "\n"
        
        if filtered_examples.get('morphology'):
            report += "üî§ –ü–†–ò–ú–ï–†–´ –§–†–ê–ó, –û–¢–§–ò–õ–¨–¢–†–û–í–ê–ù–ù–´–• –ü–û –ú–û–†–§–û–õ–û–ì–ò–ò (<5 –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤):\n"
            for i, example in enumerate(filtered_examples['morphology'], 1):
                report += f"  {i}. \"{example}...\"\n"
            report += "\n"
    
    report += "=" * 80 + "\n"
    report += "üéØ –ù–ê–°–¢–†–û–ô–ö–ò –ê–ù–ê–õ–ò–ó–ê\n"
    report += "=" * 80 + "\n\n"
    report += f"‚úÖ –ü–æ—Ä–æ–≥ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞: {SEMANTIC_THRESHOLD*100:.0f}%\n"
    report += f"‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –≤–∫–ª—é—á–µ–Ω–∞\n"
    report += f"‚úÖ –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤–∫–ª—é—á–µ–Ω–∞\n"
    report += f"‚úÖ –ú–∞–∫—Å–∏–º—É–º –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä: {MAX_POSITIVE_MATCHES}\n"
    report += f"‚úÖ –ú–∞–∫—Å–∏–º—É–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä: {MAX_NEGATIVE_MATCHES}\n"
    report += f"‚úÖ –î–∏–∞–ø–∞–∑–æ–Ω –∏—Ç–æ–≥–æ–≤—ã—Ö –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤: {MIN_PERCENTAGE}% - {MAX_PERCENTAGE}%\n\n"

    # –ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π
    for comp, data in analysis.items():
        if comp == '_detailed_stats':  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            continue
            
        max_score = data["max_score"]
        current_score = data["total_score"]
        
        # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
        if max_score > 0:
            percentage = (current_score / max_score * 100)
            percentage = max(percentage, MIN_PERCENTAGE)
            percentage = min(percentage, MAX_PERCENTAGE)
        else:
            percentage = 0

        # –£—Ä–æ–≤–Ω–∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
        if percentage >= 70:
            level = "–í—ã—Å–æ–∫–∏–π"
        elif percentage >= 40:
            level = "–°—Ä–µ–¥–Ω–∏–π"
        elif percentage >= 0:
            level = "–ù–∏–∑–∫–∏–π"
        else:
            level = "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–π"

        report += "=" * 80 + "\n"
        report += f"üèÜ –ö–û–ú–ü–ï–¢–ï–ù–¶–ò–Ø: {comp}\n"
        report += "=" * 80 + "\n"
        report += f"–û–±—â–∏–π –±–∞–ª–ª: {current_score:.1f} –∏–∑ {max_score} ({percentage:.1f}% - {level} —É—Ä–æ–≤–µ–Ω—å)\n\n"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏
        comp_stat = competency_stats.get(comp, {})
        if comp_stat:
            report += f"üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–ê–õ–ò–ó–ê –ö–û–ú–ü–ï–¢–ï–ù–¶–ò–ò:\n"
            report += f"   –í—Å–µ–≥–æ –º–∞—Ä–∫–µ—Ä–æ–≤: {comp_stat.get('total_markers', 0)}\n"
            report += f"   –í—Å–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π: {comp_stat.get('total_comparisons', 0)}\n"
            report += f"   –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {comp_stat.get('matches_found', 0)}\n"
            report += f"   –ù–∏–∂–µ –ø–æ—Ä–æ–≥–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞: {comp_stat.get('matches_below_threshold', 0)}\n"
            report += f"   –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É: {comp_stat.get('contextually_irrelevant', 0)}\n\n"

        for indicator, ind_data in data["indicators"].items():
            # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
            if ind_data['max_score'] > 0:
                ind_percentage = (ind_data['score'] / ind_data['max_score'] * 100)
                ind_percentage = max(ind_percentage, MIN_PERCENTAGE)
                ind_percentage = min(ind_percentage, MAX_PERCENTAGE)
            else:
                ind_percentage = 0
                
            report += f"üéØ –ò–ù–î–ò–ö–ê–¢–û–†: {indicator}\n"
            report += f"–ë–∞–ª–ª: {ind_data['score']:.1f} –∏–∑ {ind_data['max_score']} ({ind_percentage:.1f}%)\n"
            
            # –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
            detailed_ind_stats = ind_data.get('detailed_stats', {})
            if detailed_ind_stats:
                report += f"\nüìä –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–ù–î–ò–ö–ê–¢–û–†–ê:\n"
                report += f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤: {detailed_ind_stats.get('positive_markers', 0)}\n"
                report += f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤: {detailed_ind_stats.get('negative_markers', 0)}\n"
                report += f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π: {detailed_ind_stats.get('positive_comparisons', 0)}\n"
                report += f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π: {detailed_ind_stats.get('negative_comparisons', 0)}\n"
                report += f"   –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {detailed_ind_stats.get('positive_matches', 0)}\n"
                report += f"   –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {detailed_ind_stats.get('negative_matches', 0)}\n"
                report += f"   –ù–∏–∂–µ –ø–æ—Ä–æ–≥–∞: {detailed_ind_stats.get('below_threshold', 0)}\n"
                report += f"   –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É: {detailed_ind_stats.get('contextually_filtered', 0)}\n"
                
                # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –º–∞—Ä–∫–µ—Ä–∞
                marker_analysis = detailed_ind_stats.get('marker_analysis', {})
                if marker_analysis:
                    report += f"\nüîç –ü–û–î–†–û–ë–ù–´–ô –ê–ù–ê–õ–ò–ó –ú–ê–†–ö–ï–†–û–í:\n"
                    for marker_key, marker_data in marker_analysis.items():
                        marker_type = "–ü–û–ó–ò–¢–ò–í–ù–´–ô" if marker_key.startswith('pos_') else "–ù–ï–ì–ê–¢–ò–í–ù–´–ô"
                        report += f"\n   üìå {marker_type} –ú–ê–†–ö–ï–†: \"{marker_data.get('marker_text', '')[:80]}...\"\n"
                        report += f"      –í–µ—Å –±–∞–ª–ª–∞: {marker_data.get('score_weight', 0)}\n"
                        report += f"      –°—Ä–∞–≤–Ω–µ–Ω–∏–π: {marker_data.get('comparisons', 0)}\n"
                        report += f"      –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(marker_data.get('matches', []))}\n"
                        report += f"      –ù–∏–∂–µ –ø–æ—Ä–æ–≥–∞: {marker_data.get('below_threshold_count', 0)}\n"
                        report += f"      –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É: {marker_data.get('contextually_filtered_count', 0)}\n"
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ –º–∞—Ä–∫–µ—Ä–∞
                        marker_matches = marker_data.get('matches', [])
                        if marker_matches:
                            report += f"      üéØ –ù–ê–ô–î–ï–ù–ù–´–ï –°–û–í–ü–ê–î–ï–ù–ò–Ø:\n"
                            for i, match in enumerate(marker_matches, 1):
                                report += f"         {i}. \"{match['found'][:120]}...\"\n"
                                report += f"            –°—Ö–æ–¥—Å—Ç–≤–æ: {match['similarity']:.1%}, –ë–∞–ª–ª: {match['score']:.2f}\n"

            # –ü—Ä–∏–º–µ—Ä—ã –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ—è–≤–ª–µ–Ω–∏–π
            if ind_data['positive']['examples']:
                report += f"\n‚úÖ –õ–£–ß–®–ò–ï –ü–û–ó–ò–¢–ò–í–ù–´–ï –ü–†–û–Ø–í–õ–ï–ù–ò–Ø:\n"
                for i, example in enumerate(ind_data['positive']['examples'], 1):
                    report += f"  {i}. –ù–ê–ô–î–ï–ù–û: \"{example['found'][:150]}...\"\n"
                    report += f"     –ú–ê–†–ö–ï–†: \"{example['original'][:80]}...\"\n"
                    report += f"     –°–•–û–î–°–¢–í–û: {example['similarity']:.1%}, –ë–ê–õ–õ: {example['score']:.2f}\n"
                    report += f"     –ú–ï–¢–û–î: {example['method']}\n\n"

            # –ü—Ä–∏–º–µ—Ä—ã –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ—è–≤–ª–µ–Ω–∏–π
            if ind_data['negative']['examples']:
                report += f"‚ùå –ù–ï–ì–ê–¢–ò–í–ù–´–ï –ü–†–û–Ø–í–õ–ï–ù–ò–Ø:\n"
                for i, example in enumerate(ind_data['negative']['examples'], 1):
                    report += f"  {i}. –ù–ê–ô–î–ï–ù–û: \"{example['found'][:150]}...\"\n"
                    report += f"     –ú–ê–†–ö–ï–†: \"{example['original'][:80]}...\"\n"
                    report += f"     –°–•–û–î–°–¢–í–û: {example['similarity']:.1%}, –ë–ê–õ–õ: -{example['score']:.2f}\n"
                    report += f"     –ú–ï–¢–û–î: {example['method']}\n\n"

            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if ind_data['courses']:
                report += f"üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –†–ê–ó–í–ò–¢–ò–Ø:\n"
                for course in ind_data['courses']:
                    report += f"   - {course}\n"

            report += "\n" + "-" * 70 + "\n\n"

        report += "\n"

    return report 